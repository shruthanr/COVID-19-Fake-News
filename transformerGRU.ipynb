{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aCC_q5jVRW0K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCC_q5jVRW0K",
    "outputId": "a948b2af-5006-4b6d-f123-955172d9a88b"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8n95w3mKSAQA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "8n95w3mKSAQA",
    "outputId": "def940dc-02d3-48e3-daff-826a23ebba85"
   },
   "outputs": [],
   "source": [
    "# !pip install -U torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "QIUHjwOtRcQk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QIUHjwOtRcQk",
    "outputId": "b6003f8d-4c9a-4dda-d9eb-26c2959d7201"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gTluvfNCRkAn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gTluvfNCRkAn",
    "outputId": "6eac2f75-293c-4b83-cb40-411000bd40b3"
   },
   "outputs": [],
   "source": [
    "# cd 'drive'/'My Drive'/'Datasets'/'COVIDNews'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c2438a-45f3-4d09-b519-acc154bc613e",
   "metadata": {},
   "source": [
    "# Imports and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0781eba0-7385-4dba-8586-0d4f0e3aec61",
   "metadata": {
    "id": "0781eba0-7385-4dba-8586-0d4f0e3aec61"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c73c831-9f03-4188-87f3-875a12123eea",
   "metadata": {
    "id": "5c73c831-9f03-4188-87f3-875a12123eea"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5002d74-f9e1-425b-add9-d37cd222216c",
   "metadata": {
    "id": "a5002d74-f9e1-425b-add9-d37cd222216c"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ea20ad-48ac-474a-8e64-2bfe813ee498",
   "metadata": {
    "id": "06ea20ad-48ac-474a-8e64-2bfe813ee498"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Constraint_English_Train - Sheet1.csv\")\n",
    "val = pd.read_csv(\"Constraint_English_Val - Sheet1.csv\")\n",
    "test = pd.read_csv(\"english_test_with_labels - Sheet1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a071802-41eb-4fa3-b937-7208bad6a8f5",
   "metadata": {
    "id": "5a071802-41eb-4fa3-b937-7208bad6a8f5"
   },
   "outputs": [],
   "source": [
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "\n",
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ee5f16a-3d16-4d2b-8e1d-d3249f0e4451",
   "metadata": {
    "id": "3ee5f16a-3d16-4d2b-8e1d-d3249f0e4451"
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Field, TabularDataset, BucketIterator, LabelField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a24fa6a8-8c64-4508-bbb6-920c5cf6290c",
   "metadata": {
    "id": "a24fa6a8-8c64-4508-bbb6-920c5cf6290c"
   },
   "outputs": [],
   "source": [
    "TEXT = Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "\n",
    "LABEL = LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06b3299a-5629-4260-86f6-c4e57cba801f",
   "metadata": {
    "id": "06b3299a-5629-4260-86f6-c4e57cba801f"
   },
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = TabularDataset.splits(\n",
    "    path = \"./\",\n",
    "    train=\"Constraint_English_Train - Sheet1.csv\",\n",
    "    validation=\"Constraint_English_Val - Sheet1.csv\",\n",
    "    test=\"english_test_with_labels - Sheet1.csv\",\n",
    "    format='csv',\n",
    "    fields={\"tweet\": (\"tweet\", TEXT), \"label\" : (\"label\", LABEL)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7d88227-2ed6-4032-b6d5-14526ea9f2b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7d88227-2ed6-4032-b6d5-14526ea9f2b3",
    "outputId": "3e73ce74-77aa-4b2c-c44e-9ac6b138284f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 6420\n",
      "Number of validation examples: 2140\n",
      "Number of testing examples: 2140\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(val_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3094d5ed-a223-49d4-b76a-da2d7ace2f11",
   "metadata": {
    "id": "3094d5ed-a223-49d4-b76a-da2d7ace2f11"
   },
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb08f1e6-9d53-492c-bca9-874e955b22d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb08f1e6-9d53-492c-bca9-874e955b22d4",
    "outputId": "f449a685-b5b1-41fe-81c9-6b9a22e22708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'real': 0, 'fake': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8af5415c-d74d-496d-ace0-4f43c3da4511",
   "metadata": {
    "id": "8af5415c-d74d-496d-ace0-4f43c3da4511"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, val_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edf2b1b6-a855-47f9-aaaa-d72002e04dea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edf2b1b6-a855-47f9-aaaa-d72002e04dea",
    "outputId": "bb4d5bfb-0b6f-4cf8-a40b-571e58c05ece"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27159a4-d2a9-4f4a-bca9-f08d8fa4b043",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "775b79c4-7cc9-43dc-bb11-9951e8783e4a",
   "metadata": {
    "id": "775b79c4-7cc9-43dc-bb11-9951e8783e4a"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BERTGRUSentiment(nn.Module):\n",
    "    def __init__(self, bert, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            embedded = self.bert(text)[0]\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        _, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #hidden = [n layers * n directions, batch size, emb dim]\n",
    "        \n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "                \n",
    "        #hidden = [batch size, hid dim]\n",
    "        \n",
    "        output = self.out(hidden)\n",
    "        \n",
    "        #output = [batch size, out dim]\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6b253c9-1628-4d96-b6db-75eaec29b0b5",
   "metadata": {
    "id": "b6b253c9-1628-4d96-b6db-75eaec29b0b5"
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "model = BERTGRUSentiment(bert,\n",
    "                         HIDDEN_DIM,\n",
    "                         OUTPUT_DIM,\n",
    "                         N_LAYERS,\n",
    "                         BIDIRECTIONAL,\n",
    "                         DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34727e61-9c8c-4242-a938-d2d41603c008",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34727e61-9c8c-4242-a938-d2d41603c008",
    "outputId": "fc126ab2-e91b-49a4-a4be-9941024461ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 112,241,409 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53323517-7225-4fd3-9010-bda66ec164f3",
   "metadata": {
    "id": "53323517-7225-4fd3-9010-bda66ec164f3"
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1585809b-d939-42e4-9c4a-a77cc79bfee3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1585809b-d939-42e4-9c4a-a77cc79bfee3",
    "outputId": "92886a35-5639-4a45-dd27-3fbd9dff1126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,759,169 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b26b5a8-ea89-4c59-8d57-cb5175818f02",
   "metadata": {
    "id": "0b26b5a8-ea89-4c59-8d57-cb5175818f02"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60d752a5-10cf-410d-94e7-2de881d3af9a",
   "metadata": {
    "id": "60d752a5-10cf-410d-94e7-2de881d3af9a"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "265498c1-b6bb-43e3-823e-40cee4c613cc",
   "metadata": {
    "id": "265498c1-b6bb-43e3-823e-40cee4c613cc"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.tweet).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "089e1a75-cd5c-4b24-b3b6-5e05dade344f",
   "metadata": {
    "id": "089e1a75-cd5c-4b24-b3b6-5e05dade344f"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.tweet).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4169013c-56ff-47a2-bb4d-f0ebe0df23ae",
   "metadata": {
    "id": "4169013c-56ff-47a2-bb4d-f0ebe0df23ae"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192893cd-422e-4277-b28d-fc7b901edf9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "192893cd-422e-4277-b28d-fc7b901edf9c",
    "outputId": "ca754a2b-1ef8-4696-f76f-222e3caf3945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 started\n",
      "Epoch: 01 | Epoch Time: 2m 43s\n",
      "\tTrain Loss: 0.345 | Train Acc: 84.23%\n",
      "\t Val. Loss: 0.215 |  Val. Acc: 91.91%\n",
      "Epoch 1 started\n",
      "Epoch: 02 | Epoch Time: 2m 48s\n",
      "\tTrain Loss: 0.174 | Train Acc: 93.31%\n",
      "\t Val. Loss: 0.148 |  Val. Acc: 95.07%\n",
      "Epoch 2 started\n",
      "Epoch: 03 | Epoch Time: 2m 43s\n",
      "\tTrain Loss: 0.141 | Train Acc: 94.67%\n",
      "\t Val. Loss: 0.127 |  Val. Acc: 95.79%\n",
      "Epoch 3 started\n",
      "Epoch: 04 | Epoch Time: 2m 48s\n",
      "\tTrain Loss: 0.100 | Train Acc: 96.38%\n",
      "\t Val. Loss: 0.112 |  Val. Acc: 96.59%\n",
      "Epoch 4 started\n",
      "Epoch: 05 | Epoch Time: 2m 44s\n",
      "\tTrain Loss: 0.077 | Train Acc: 97.47%\n",
      "\t Val. Loss: 0.122 |  Val. Acc: 95.76%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    print(f\"Epoch {epoch} started\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "        \n",
    "    end_time = time.time()\n",
    "        \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'trans_model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e38780d-6bc9-480f-bf30-82c319c36c60",
   "metadata": {
    "id": "c44ea370-90c6-4dc6-a75c-ecd175ba8375"
   },
   "source": [
    "# Test on best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcee9457-5820-4028-8dd2-c4db25001436",
   "metadata": {
    "id": "dcee9457-5820-4028-8dd2-c4db25001436"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('trans_model.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a647749-99c2-4496-bf53-a16849f82068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.108 | Test Acc: 96.03%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b0152b-dd04-4e82-bcd5-789deeacd731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
